{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Study on Interpretability - Main Sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "***BEFORE YOU BEGIN***: \n",
    "\n",
    "* Make sure this is running on the **Python 3.6 Kernel** (not Python 3). This can be changed in the 'Kernel' menu above.\n",
    "* Go to \"Cell\" -> \"Run All\" to start executing preliminary commands in the background while you read the instructions below.\n",
    "\n",
    "--- \n",
    "\n",
    "### Description:\n",
    "    \n",
    "Throughout this study we will be using the 'Online News Popularity' dataset. \n",
    "\n",
    "Each instance in this dataset is a news article published in mashable.com, characterized by 53 features describing its length, contents, polarity and some metadata. We will provide short descriptions of each feature below. The data consists of 33,510 examples (80%/20% training/testing). \n",
    "\n",
    "The task is to predict the *channel* ('world', 'tech', 'entertainment', 'business', 'social media' or 'lifestyle') in which each news article was published. \n",
    "\n",
    "The 'Preliminaries' section below is a typical ML pipeline: data loading, description, model training and evaluation.\n",
    "\n",
    "After the model is trained, the interpretabilty tool will be instantatied and used to explain the predictions of this model.\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "* Please read carefully and **execute all cells** (if you did \"Run All\", the first part will already be executed, no need to run those again).\n",
    "* At the end of each section you will find a some questions, which you can answer in the empty cells provided below them.\n",
    "* If you have any questions, please let the researcher now.\n",
    "* Feel free to refer to the tutorial if you need a reminder of any of the concepts introduced there.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries: Data, Features, Meta-Features & Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is the 'channel', which has 6 classes, not evenly distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.data import load_online_news\n",
    "X, Y, df, feature_groups, feature_desc = load_online_news(target='channel', transform='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has 53 features, which could be hard to analyze simultaenously. Fortunately, there's many variables that encode similar aspects of the input, like length or polarity. A faily simple and natural grouping of features is shown below.\n",
    "\n",
    "**Note**: there is no need to read the description of all features. Should you need them, you can scroll back here and read those that might be relevant for questions later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,idxs in enumerate(feature_groups.idxs):\n",
    "    print('\\nFeatue Group {}: {}'.format(i, feature_groups.names[i].upper()))\n",
    "    for j in idxs:\n",
    "        print('    {:30}\\t->\\t{}'.format(X.names[j], feature_desc[X.names[j]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we next show basic statistics of each feature. Again, this information is not crucial for answering the questions below, and is provided only for reference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,4))\n",
    "cols = np.array(df.columns.tolist())[np.concatenate(feature_groups.idxs)]\n",
    "df.reindex(columns = cols).boxplot(grid=False, rot = 90, ax = ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the integer-valued features have been scaled (by taking log)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Training\n",
    "\n",
    "We will train a classifier on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import src.classifiers\n",
    "classifier = src.classifiers.factory(dataset='online_news', model_type=2, load_trained=True)\n",
    "#classifier.fit(X.train, Y.train)\n",
    "print('Accuracy on train: {:4.2f}%'.format(100*classifier.score(X.train, Y.train)))\n",
    "print('Accuracy on test: {:4.2f}%'.format(100*classifier.score(X.test, Y.test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'meaning of life' is 42, \" This error was purposely added to stop automatic execution. Ignore and continue below.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PART 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Insantiate Explainers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a Weight of Evidence estimator, and an explainer wrapper around it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "from src.utils import range_plot\n",
    "from src.explainers import WOE_Explainer\n",
    "from src.woe import woe_gaussian\n",
    "\n",
    "woe_estimator =  woe_gaussian(classifier, X.train, classes = range(len(Y.names)), cond_type='nb')\n",
    "\n",
    "woeexplainer = WOE_Explainer(classifier, woe_estimator,\n",
    "                             total_woe_correction=True,\n",
    "                             classes=Y.names, features=X.names,\n",
    "                             X=X.train, Y=Y.train,\n",
    "                             featgroup_idxs = feature_groups.idxs,\n",
    "                             featgroup_names = feature_groups.names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before explaining specific examples, let's look at the model's prior class probabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(7,4))\n",
    "woeexplainer.plot_priors(normalize = None, ax = ax) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in the tutorial, lower prior log odds require stronger evidence to overcome them. In this case, 'social media' and 'lifestyle' have much lower prior log odds that the other classes (because the data is unbalanced!).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's pick an example from the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_1 = 4 # Don't change this\n",
    "x_1   = X.test[idx_1].reshape(1,-1)\n",
    "y_1   = Y.test[idx_1].reshape(1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first set of questions on this section will be based on this example.\n",
    "\n",
    "Let's see what the model predicts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class = classifier.predict(x_1)[0]\n",
    "pred_proba = classifier.predict_proba(x_1)[0][pred_class]\n",
    "\n",
    "print(f\"Predicted class: {Y.names[pred_class]} (prob: {pred_proba})\")\n",
    "print(f\"True class:      {Y.names[y_1.squeeze()]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at this example's feature values compared to the training data (aggregated by class):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "woeexplainer.plot_ranges(x_1, groupby='predicted', annotate='value', rescale=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The boxplots have been centered and scaled in this plot to facilitate visualization. \n",
    "\n",
    "While the actual values of the features are not too important, the position of the black dots (the example being explained) with respect to the training is useful to understand how this instance relates other examples.\n",
    "\n",
    "Now we explain the model's prediction for this example, using the Explainer tool.\n",
    "\n",
    "**Attention**: Here, **you have to choose** whether to visualize the explanation by features of by feature groups. Don't worry! You can switch as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uncomment one to select TYPE of explanation unit\n",
    "\n",
    "#explanation_units = 'features' \n",
    "#explanation_units = 'feature_groups' \n",
    "\n",
    "e = woeexplainer.explain(x_1,y_1, totext=False, units=explanation_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q1: In plain English, what would you say are main characteristics of this news article that the model is relying on to make its prediction?\n",
    "\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The prediction is mostly based on these chacterteristics:\n",
    "# 1. The article ...\n",
    "# 2. The article ...\n",
    "# 3. The article ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clear the variables before moving on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'idx_1' in globals(): del idx_1\n",
    "if 'explanation_units' in globals(): del explanation_units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will now take a look at a different example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_2 = 20 # Don't change this \n",
    "x_2   = X.test[idx_2].reshape(1,-1)\n",
    "y_2   = Y.test[idx_2].reshape(1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to look at the feature boxplots for this example, uncomment the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# woeexplainer.plot_ranges(x_2, groupby='predicted', annotate='value', rescale=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, you can **select** how to display the explanation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uncomment one to select TYPE of explanation unit\n",
    "\n",
    "#explanation_units = 'features' \n",
    "#explanation_units = 'feature_groups'\n",
    "\n",
    "e = woeexplainer.explain(x_2, y_2, units=explanation_units, totext=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q2: The model is not very confident about its prediction. Why do you think that is?\n",
    "\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This prediction is not very confident because ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q3: In plain English, how would you modify this article to make the model more confident of its prediction, while not changing the article 'too much'?\n",
    "\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I would change ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second part of the study, we will continue working with the same dataset and model, but will now try to answer a different set of questions.\n",
    "\n",
    "Let's pick another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_3 = 55 # Don't change this.\n",
    "x_3   = X.test[idx_3].reshape(1,-1)\n",
    "y_3   = Y.test[idx_3].reshape(1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to look at the feature boxplots for this example, uncomment the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#woeexplainer.plot_ranges(x_3, groupby='predicted', annotate='value', rescale=True)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the model predicts in this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class = classifier.predict(x_3)[0]\n",
    "pred_proba = classifier.predict_proba(x_3)[0][pred_class]\n",
    "\n",
    "print(f\"Predicted class: {Y.names[pred_class]} (prob: {pred_proba})\")\n",
    "print(f\"True class:      {Y.names[y_3.squeeze()]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explain it. Now, **you must choose** whether to produce a **sequential** or **one-shot** explanation. Again, feel free to change between these as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_explanation = # Choose True or False\n",
    "\n",
    "e = woeexplainer.explain(x_3, y_3, units='feature_groups', totext=False,\n",
    "                         sequential=sequential_explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q4: Why do you think the model didn't predict 'entertainment','lifestyle' or 'tech' instead?\n",
    "\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It didn't predict these other classes because: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q5: Why do you think the model didn't predict 'world' instead?\n",
    "\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It didn't predict 'world' because:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q6: Suppose this classifier had been trained on a dataset with very few examples labeled 'business', but was otherwise identical. Do you think the prediction for this example would change? If so, what class would be predicted instead?\n",
    "\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The prediction [would|wouldn't] change ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--- ##### Q6: Suppose there is another news article with the same exact 'keywords' as this one, but all the other features have changed so that they are equally likely for 'world' than for other classes (i.e., they are not predictive of the class). For this modified article, how much more likely do you think it is that the model would predict 'world' instead of other classes?\n",
    "\n",
    "Answer:\n",
    "\n",
    "--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow-Up Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The researcher will now ask you a few general follow-up questions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
